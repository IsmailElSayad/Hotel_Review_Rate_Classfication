{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hotel_review_SOTA.ipynb","provenance":[{"file_id":"1qbryiW7Z8EtCEbdNB2qq6z3jUHpVdhfT","timestamp":1607505670352}],"collapsed_sections":[],"authorship_tag":"ABX9TyPjLdmgZle+nkXPCsIXNFoi"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eu7Pv545n9Cl","executionInfo":{"status":"ok","timestamp":1607678595723,"user_tz":-120,"elapsed":264986,"user":{"displayName":"Bilal H","photoUrl":"","userId":"17387886967102525476"}},"outputId":"685afeaf-6a93-4802-e636-9fe138ebe16f"},"source":["from numpy import loadtxt\n","import pandas as pd\n","\n","# to feed and train using the train csv\n","data_train = pd.read_csv('sentiment_dataset_train.csv')\n","# to test accuracy using the dev csv\n","data_dev = pd.read_csv('sentiment_dataset_dev.csv')\n","# the data to predict with exist result to get accuracy\n","data_test = pd.read_csv('sentiment_dataset_test.csv')\n","# dataset.head()\n","dataset = data_train.append(data_dev)\n","dataset = dataset.append(data_test)\n","\n","train_len = len(data_train)\n","dev_len = len(data_dev)\n","del data_train\n","del data_dev\n","# import gc\n","# gc.collect()\n","# data_train=pd.DataFrame()\n","# data_dev=pd.DataFrame()\n","\n","# select only relevant columns\n","#dataset = dataset[[\"review\", \"rating\"]]\n","\n","# create doc2vec vector columns\n","from gensim.test.utils import common_texts\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","\n","documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(dataset[\"review\"].apply(lambda x: x.split(\" \")))]\n","\n","# train a Doc2Vec model with our text data\n","model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n","\n","# transform each document into a vector data\n","doc2vec_df = dataset[\"review\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n","doc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\n","dataset = pd.concat([dataset, doc2vec_df], axis=1)\n","\n","\n","# add tf-idfs columns\n","# TF computes the classic number of times the word appears in the text\n","# IDF computes the relative importance of this word which depends on how many texts the word can be found\n","# We add TF-IDF columns for every word that appear in at least 10 different texts to filter some of them and reduce the size of the final output.\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","tfidf = TfidfVectorizer(min_df = 10)\n","tfidf_result = tfidf.fit_transform(dataset[\"review\"]).toarray()\n","tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n","tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n","tfidf_df.index = dataset.index\n","dataset = pd.concat([dataset, tfidf_df], axis=1)\n","\n","# feature selection\n","label = \"rating\"\n","ignore_cols = [label, \"id\", \"review\"]\n","features = [c for c in dataset.columns if c not in ignore_cols]\n","\n","# split the data into train and test for test accuracy\n","from sklearn.ensemble import RandomForestClassifier\n","# from sklearn.model_selection import train_test_split\n","# X_train, X_test, y_train, y_test = train_test_split(dataset[features], dataset[label], test_size = 0.20, random_state = 1)  # 70% training and 30% test\n","X_train, X_dev = dataset[features][:train_len], dataset[features][train_len:]\n","X_dev, X_test = X_dev[:dev_len], X_dev[dev_len:]\n","y_train, y_dev = dataset[label][:train_len], dataset[label][train_len:]\n","y_dev = y_dev[:dev_len]\n","del dataset\n","\n","\n","# classification model we are going to use is the logistic regression\n","from sklearn.linear_model import LogisticRegression\n","# Create LogisticRegression classifer object\n","clf = LogisticRegression(max_iter=600)\n","# Train Classifer\n","clf = clf.fit(X_train,y_train)\n","#Predict the response for test dataset\n","y_test_pred = clf.predict(X_test)\n","# Model Accuracy, how often is the classifier correct?\n","y_dev_pred = clf.predict(X_dev)\n","# Model Accuracy, how often is the classifier correct?\n","from sklearn import metrics\n","# print(\"Accuracy:\",clf.score(X_dev, y_dev))\n","print(\"Accuracy:\", metrics.accuracy_score(y_dev, y_dev_pred))\n","\n","data_test_result = pd.concat([data_test, pd.DataFrame(y_test_pred, columns=['predictated_rating'])], axis=1)\n","print(\"Test Result Data with Predictated Ratings:\")\n","print(data_test_result)\n","# if we want to save data in csv\n","# df.to_csv(file_name, sep=',', encoding='utf-8')\n","\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Accuracy: 0.7351927295518647\n","Test Result Data with Predictated Ratings:\n","        id  ... predictated_rating\n","0        0  ...                3.0\n","1        1  ...                4.0\n","2        3  ...                2.0\n","3        4  ...                1.0\n","4        6  ...                4.0\n","...    ...  ...                ...\n","3317  3812  ...                4.0\n","3318  3813  ...                1.0\n","3319  3814  ...                4.0\n","3320  3815  ...                1.0\n","3321  3817  ...                5.0\n","\n","[3322 rows x 3 columns]\n"],"name":"stdout"}]}]}